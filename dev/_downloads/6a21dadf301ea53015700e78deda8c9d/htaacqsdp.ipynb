{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# HTAAC-QSDP\nHadamard Test and Approximate Amplitude Constraint Quantum Semidefinite Programming ([1]_) (HTAAC-QSDP) quantum optimization algorithm for MaxCut using TensorLy-Quantum.\nTensorLy-Quantum provides a Python interface \nto build TT-tensor network circuit simulator \nfor large-scale simulation of variational quantum circuits\nwith full Autograd support similar to traditional PyTorch Neural Networks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tlquantum as tlq\nimport torch\nimport itertools\n\n\ntorch.manual_seed(0)\n\ndevice = 'cuda:0'\n#device = 'cpu'\ntorch.cuda.set_device(device)\ndtype = torch.complex64\nconstraint_dtype = torch.float32\n\nncontraq = 2 #number of qubits to pre-contract into single core\nncontral = 5 #number of layers to pre-contract into a single core\n\n### hyperparameters simulation\nnepochs = 300 # number of epochs per experiment\nreps = 1 # number of repititions of experiment (full runs)\n\n### hyperparamters optimizer\nlr = 0.01 # learning rate\n\n### circuit hyperparameters\nnqubits = 10 # number of qubits\ngate_rep = 120 # number of gates per qubit or circuit-depth\nps_order = 2\nnterms = 800 # number of variables in SDP\nW_divisor = 1 # divisor coefficient, not relevant for GSET graphs\n\n### graph hyperparameters\nalpha = 0.01 # unitary phase\nU_P_multiplier = 1.0\n\n### G11, G12, and G13 Graph Parameters\n#name = 'Graphs/G11' # graph name\n#sdp_value = 542 # best-known classical SDP value\n#coeff_base = 100 #10 # size of coefficient\n#reg = 1.2\n\n### G14 and G15 Graph Parameters\n#name = 'Graphs/G14' # graph name\n#sdp_value = 2922 # best-known classical SDP value\n#coeff_base = 100 #10 # size of coefficient\n#reg = 3.0\n\n### G20 and G21 Graph Parameters\nname = 'Graphs/G20' # graph name\nsdp_value = 838 # best-known classical SDP value\ncoeff_base = 50 #10 # size of coefficient\nreg = 3.0\n\n### build trivial input state as a tensor\nstate = tlq.spins_to_tt_state([0 for i in range(nqubits)], device=device, dtype=dtype)\nstate = tlq.qubits_contract(state, ncontraq)\n\n\n### Alternative constraint vectors (dot product) instead of matrices (inner product with state)\npauli_obs_vec = []\nfor i in range(nqubits):\n    vec = torch.zeros(1, 2**nqubits, dtype=constraint_dtype, device=device)\n    for j in range(0, 2**nqubits, 2**(nqubits-1-i)):\n        vec[0, j:j+2**(nqubits-1-i)] = (-1)**(j//2**(nqubits-1-i))\n    pauli_obs_vec.append(vec)\nreset = True\nfor i in range(2,ps_order+1):\n    for gate_indices in list(itertools.combinations(list(range(nqubits)), i)):\n        for ind in range(nqubits):\n            if ind in gate_indices:\n                if reset:\n                    op = pauli_obs_vec[ind]\n                    reset = False\n                else:\n                    op = op*pauli_obs_vec[ind]\n        pauli_obs_vec.append(op)\n        reset = True\nnconstraints = len(pauli_obs_vec)\ncoeff = coeff_base*alpha/nconstraints\n\nconstraint_matrix = torch.cat(pauli_obs_vec, dim=0)\ndel pauli_obs_vec, vec, op\n\n\n### build the two unitary matrices\n\nvertices1 = torch.load(name+'_wspins1.pt').to(torch.int64).to(device)\nvertices2 = torch.load(name+'_wspins2.pt').to(torch.int64).to(device)\nweights = torch.load(name+'_weights.pt').to(device)\n\nweights = weights/W_divisor\n# half of the terms are missing because we don't add the reflection, but we save memory and just multiply by 2 below\nU_W_sparse = alpha*torch.sparse_coo_tensor([vertices1.tolist(), vertices2.tolist()], weights, (2**nqubits, 2**nqubits), dtype=constraint_dtype)\n### V is generator of the population balancing unitary U_P\nbins = torch.bincount(torch.cat((vertices1, vertices2)))\nmax_bins = torch.max(bins)\nU_P_vectorized = torch.zeros((1, 2**nqubits), dtype=dtype, device=device)\nfor i in range(2**nqubits):\n    if i < nterms:\n        U_P_vectorized[0,i] = (-(max_bins-bins[i])/reg)\n    else:\n        U_P_vectorized[0,i] = (-max_bins/reg)\n\nU_P_vectorized = torch.imag(torch.exp(1j*alpha*U_P_vectorized)) * U_P_multiplier\n\n\nfor rep in range(reps):\n\n    ### build the unitary gates layer by layer\n    ### rebuild each rep to get new circuit/random initialization\n    CZ0 = tlq.BinaryGatesUnitary(nqubits, ncontraq, tlq.cz(device=device, dtype=dtype), 0)\n    CZ1 = tlq.BinaryGatesUnitary(nqubits, ncontraq, tlq.cz(device=device, dtype=dtype), 1)\n    unitaries = []\n    for r in range(gate_rep):\n        unitaries += [tlq.UnaryGatesUnitary(nqubits, ncontraq, device=device, dtype=dtype), CZ0, tlq.UnaryGatesUnitary(nqubits, ncontraq, device=device, dtype=dtype), CZ1]\n    circuit = tlq.TTCircuit(unitaries, ncontraq, ncontral)\n    opt = torch.optim.Adam(circuit.parameters(), lr=lr, amsgrad=True) # basic ADAM AMSGrad optimizer\n\n    for epoch in range(nepochs):\n\n        output_state = circuit.to_ket(state).real\n\n        ### loss from the objective function and population balancing unitaries\n        loss = torch.sparse.mm(U_W_sparse, output_state)\n        loss = 2*torch.mm(output_state.T, loss) # multiply by 2 because we don't have the reflected terms\n\n        with torch.no_grad():\n            cut_vec = tlq.calculate_cut(torch.sign(torch.real(output_state[0:nterms])), vertices1, vertices2, weights, get_cut=True).data\n            print('Epoch Number ' + str(epoch), flush=True)\n            print('Ratio of HTAAC-QSDP cut to classical SDP cut ' + str(cut_vec.item()/sdp_value), flush=True)\n            print()\n\n        ### square the state (abs val but real as these are all real states)\n        output_state = output_state**2\n        U_P_result = torch.mm(U_P_vectorized, output_state)\n        constraints = torch.sum(torch.mm(constraint_matrix, output_state)**2)\n\n        ### add the constraint loss for full backprop\n        loss = loss + U_P_result + coeff*constraints\n\n        loss.backward()\n        opt.step()\n        opt.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References\n.. [1] T. L. Patti, J. Kossaifi, A. Anandkumar, and S. F. Yelin, \"Quantum Semidefinite Programming with the Hadamard Test and Approximate Amplitude Constraints\", (2022), arXiv:2206.14999.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}